{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Dateline</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SBN_ARB_0000001</td>\n",
       "      <td>http://www.sabanews.net/ar/news200024.htm</td>\n",
       "      <td>الكونجرس الأمريكي يطالب المجتمع الدولي دعم الي...</td>\n",
       "      <td>08/ديسمبر/2009</td>\n",
       "      <td>08/ديسمبر/2009] واشنطن ـ سبأنت: طالب الكونجرس ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SBN_ARB_0000002</td>\n",
       "      <td>http://www.sabanews.net/ar/news200066.htm</td>\n",
       "      <td>مناقشة إستراتيجية التواصل الخاصة بالأجندة الوط...</td>\n",
       "      <td>08/ديسمبر/2009</td>\n",
       "      <td>08/ديسمبر/2009] صنعاء ـ سبأنت: جرى اليوم بوزار...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SBN_ARB_0000003</td>\n",
       "      <td>http://www.sabanews.net/ar/news200073.htm</td>\n",
       "      <td>نائب وزير التخطيط يلتقي بعثة الوكالة اليابانية...</td>\n",
       "      <td>08/ديسمبر/2009</td>\n",
       "      <td>08/ديسمبر/2009] صنعاء ـ سبأنت: أشاد نائب وزير ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SBN_ARB_0000004</td>\n",
       "      <td>http://www.sabanews.net/ar/news200090.htm</td>\n",
       "      <td>الناطق الرسمي: الرؤية الحكيمة للدولة في التعام...</td>\n",
       "      <td>08/ديسمبر/2009</td>\n",
       "      <td>08/ديسمبر/2009] صنعاء – سبأنت : أكد الناطق الر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SBN_ARB_0000005</td>\n",
       "      <td>http://www.sabanews.net/ar/news200092.htm</td>\n",
       "      <td>نوكيا تطرح خدمة الخرائط والملاحة في الأسواق</td>\n",
       "      <td>08/ديسمبر/2009</td>\n",
       "      <td>08/ديسمبر/2009] القاهرة ـ سبأنت: عبداللطيف الك...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID                                        URL  \\\n",
       "0  SBN_ARB_0000001  http://www.sabanews.net/ar/news200024.htm   \n",
       "1  SBN_ARB_0000002  http://www.sabanews.net/ar/news200066.htm   \n",
       "2  SBN_ARB_0000003  http://www.sabanews.net/ar/news200073.htm   \n",
       "3  SBN_ARB_0000004  http://www.sabanews.net/ar/news200090.htm   \n",
       "4  SBN_ARB_0000005  http://www.sabanews.net/ar/news200092.htm   \n",
       "\n",
       "                                            Headline        Dateline  \\\n",
       "0  الكونجرس الأمريكي يطالب المجتمع الدولي دعم الي...  08/ديسمبر/2009   \n",
       "1  مناقشة إستراتيجية التواصل الخاصة بالأجندة الوط...  08/ديسمبر/2009   \n",
       "2  نائب وزير التخطيط يلتقي بعثة الوكالة اليابانية...  08/ديسمبر/2009   \n",
       "3  الناطق الرسمي: الرؤية الحكيمة للدولة في التعام...  08/ديسمبر/2009   \n",
       "4        نوكيا تطرح خدمة الخرائط والملاحة في الأسواق  08/ديسمبر/2009   \n",
       "\n",
       "                                                Text  \n",
       "0  08/ديسمبر/2009] واشنطن ـ سبأنت: طالب الكونجرس ...  \n",
       "1  08/ديسمبر/2009] صنعاء ـ سبأنت: جرى اليوم بوزار...  \n",
       "2  08/ديسمبر/2009] صنعاء ـ سبأنت: أشاد نائب وزير ...  \n",
       "3  08/ديسمبر/2009] صنعاء – سبأنت : أكد الناطق الر...  \n",
       "4  08/ديسمبر/2009] القاهرة ـ سبأنت: عبداللطيف الك...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lxml import etree\n",
    "parser = etree.XMLParser(recover=True)\n",
    "tree = etree.parse(file_path, parser=parser)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Extracting information into a DataFrame\n",
    "rows = []\n",
    "df_columns = [\"ID\", \"URL\", \"Headline\", \"Dateline\", \"Text\"]\n",
    "\n",
    "for sabanews in root.findall('Sabanews'):\n",
    "    data = []\n",
    "    for elem in df_columns:\n",
    "        data.append(sabanews.find(elem).text if sabanews.find(elem) is not None else None)\n",
    "    rows.append(data)\n",
    "\n",
    "df_from_file = pd.DataFrame(rows, columns=df_columns)\n",
    "df_from_file.head()  # Display the first few rows of the DataFrame from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'08/ديسمبر/2009] واشنطن ـ سبأنت: طالب الكونجرس الأمريكي الإدارة الأمريكية والمجتمع الدولي تقديم الدعم والمساعدة لليمن بما يمكنه من مواجهة التحديات القائمة وتعزيز مسيرته التنموية . و دعا مجلس الشيوخ الأمريكي في قرار أصدره مؤخرا و صوت عليه أغلبية أعضائه, الرئيس الأمريكي باراك أوباما إلى دعم التنمية و الإصلاحات في اليمن.. مشددا على أهمية عدم تجاهل التحديات التي تواجهها اليمن في الآونة الأخيرة. ونبه مجلس الشيوخ الأمريكي في هذا الصدد إلى التهديدات الخطيرة التي يتعرض لها الأمن القومي الأمريكي واليمن ودول المنطقة بسبب ظاهرة الإرهاب وزعزعة الاستقرار في اليمن. وأكد وقوفه إلى جانب أمن و سلامة المواطنين اليمنيين المتضررين جراء المواجهات القائمة بما في ذلك النازحين من المدنيين الأبرياء الذين عانوا جراء الأحداث المزعزعة للاستقرار والعمليات الإرهابية. ودعا المجلس الإدارة الأمريكية و المجتمع الدولي مساعدة اليمن بكل السبل المتاحة لتعزيز قدراته في مواجهة الإرهاب والحيلولة دون تدهور أوضاعه الأمنية والحفاظ على استقراره. في حين شدد السيناتور الديمقراطي بنجامين كاردان الذي تبنى القرار مع السيناتور الجمهوري ريتشارد لوجار ان \"على الولايات المتحدة والمجتمع الدولي و اليمنيين خصوصا أن يعملوا معا لمجابهة التحديات القائمة\". سبأ'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_from_file['Text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " !\"$%'()*+,-./0123456789:;=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_`abcdefghijklmnopqrstuvwxyz{|}~§«­·»×÷،؛؟ءآأؤإئابةتثجحخدذرزسشصضطظعغـفقكلمنهوىيًٌٍَُِّْچکھ‌‍‎‏–—‘’“”•…\n",
      "Vocab_size =  160\n"
     ]
    }
   ],
   "source": [
    "text = ''.join(df_from_file['Text'].values)\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(\"Vocab_size = \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[134, 0, 120, 134, 109, 0, 124, 130, 136, 133, 0, 102, 125, 130, 107, 136, 108, 0, 102, 124, 121, 106, 105, 133]\n",
      "و صوت عليه أغلبية أعضائه\n"
     ]
    }
   ],
   "source": [
    "char_toid = { ch:i for i,ch in enumerate(chars)}\n",
    "id_tochar = { i:ch for i,ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda s: [char_toid[c] for c in s]\n",
    "decode = lambda ids: [id_tochar[id] for id in ids]\n",
    "\n",
    "print(encode(\"و صوت عليه أغلبية أعضائه\"))\n",
    "print(''.join(decode(encode(\"و صوت عليه أغلبية أعضائه\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 14,  22,  13, 114, 136, 118, 131, 107, 116,  13,  16,  14,  14,  23,\n",
      "         57,   0, 134, 106, 119, 132, 122, 132,   0, 126,   0, 118, 107, 102,\n",
      "        132, 109,  24,   0, 122, 106, 130, 107,   0, 106, 130, 129, 134, 132,\n",
      "        111, 116, 118,   0, 106, 130, 102, 131, 116, 136, 129, 136,   0, 106,\n",
      "        130, 104, 114, 106, 116, 108,   0, 106, 130, 102, 131, 116, 136, 129,\n",
      "        136, 108,   0, 134, 106, 130, 131, 111, 109, 131, 124,   0, 106, 130,\n",
      "        114, 134, 130, 136,   0, 109, 128, 114, 136, 131,   0, 106, 130, 114,\n",
      "        124, 131,   0, 134, 106, 130, 131, 118, 106, 124, 114, 108,   0, 130,\n",
      "        130, 136, 131, 132,   0, 107, 131, 106,   0, 136, 131, 129, 132, 133,\n",
      "          0, 131, 132,   0, 131, 134, 106, 111, 133, 108,   0, 106, 130, 109,\n",
      "        112, 114, 136, 106, 109,   0, 106, 130, 128, 106, 105, 131, 108,   0,\n",
      "        134, 109, 124, 117, 136, 117,   0, 131, 118, 136, 116, 109, 133,   0,\n",
      "        106, 130, 109, 132, 131, 134, 136, 108,   0,  12,   0, 134,   0, 114,\n",
      "        124, 106,   0, 131, 111, 130, 118,   0, 106, 130, 119, 136, 134, 113,\n",
      "          0, 106, 130, 102, 131, 116, 136, 129, 136,   0, 127, 136,   0, 128,\n",
      "        116, 106, 116,   0, 102, 120, 114, 116, 133,   0, 131, 103, 113, 116,\n",
      "        106,   0, 134,   0, 120, 134, 109,   0, 124, 130, 136, 133,   0, 102,\n",
      "        125, 130, 107, 136, 108,   0, 102, 124, 121, 106, 105, 133,  10,   0,\n",
      "        106, 130, 116, 105, 136, 118,   0, 106, 130, 102, 131, 116, 136, 129,\n",
      "        136,   0, 107, 106, 116, 106, 129,   0, 102, 134, 107, 106, 131, 106,\n",
      "          0, 104, 130, 135,   0, 114, 124, 131,   0, 106, 130, 109, 132, 131,\n",
      "        136, 108,   0, 134,   0, 106, 130, 104, 120, 130, 106, 112, 106, 109,\n",
      "          0, 127, 136,   0, 106, 130, 136, 131, 132,  12,  12,   0, 131, 119,\n",
      "        114, 114, 106,   0, 124, 130, 135,   0, 102, 133, 131, 136, 108,   0,\n",
      "        124, 114, 131,   0, 109, 111, 106, 133, 130,   0, 106, 130, 109, 112,\n",
      "        114, 136, 106, 109,   0, 106, 130, 109, 136,   0, 109, 134, 106, 111,\n",
      "        133, 133, 106,   0, 106, 130, 136, 131, 132,   0, 127, 136,   0, 106,\n",
      "        130, 101, 134, 132, 108,   0, 106, 130, 102, 113, 136, 116, 108,  12,\n",
      "          0, 134, 132, 107, 133,   0, 131, 111, 130, 118,   0, 106, 130, 119,\n",
      "        136, 134, 113,   0, 106, 130, 102, 131, 116, 136, 129, 136,   0, 127,\n",
      "        136,   0, 133, 115, 106,   0, 106, 130, 120, 114, 114,   0, 104, 130,\n",
      "        135,   0, 106, 130, 109, 133, 114, 136, 114, 106, 109,   0, 106, 130,\n",
      "        113, 122, 136, 116, 108,   0, 106, 130, 109, 136,   0, 136, 109, 124,\n",
      "        116, 121,   0, 130, 133, 106,   0, 106, 130, 102, 131, 132,   0, 106,\n",
      "        130, 128, 134, 131, 136,   0, 106, 130, 102, 131, 116, 136, 129, 136,\n",
      "          0, 134, 106, 130, 136, 131, 132,   0, 134, 114, 134, 130,   0, 106,\n",
      "        130, 131, 132, 122, 128, 108,   0, 107, 118, 107, 107,   0, 123, 106,\n",
      "        133, 116, 108,   0, 106, 130, 104, 116, 133, 106, 107,   0, 134, 117,\n",
      "        124, 117, 124, 108,   0, 106, 130, 106, 118, 109, 128, 116, 106, 116,\n",
      "          0, 127, 136,   0, 106, 130, 136, 131, 132,  12,   0, 134, 102, 129,\n",
      "        114,   0, 134, 128, 134, 127, 133,   0, 104, 130, 135,   0, 111, 106,\n",
      "        132, 107,   0, 102, 131, 132,   0, 134,   0, 118, 130, 106, 131, 108,\n",
      "          0, 106, 130, 131, 134, 106, 122, 132, 136, 132,   0, 106, 130, 136,\n",
      "        131, 132, 136, 136, 132,   0, 106, 130, 131, 109, 121, 116, 116, 136,\n",
      "        132,   0, 111, 116, 106, 100,   0, 106, 130, 131, 134, 106, 111, 133,\n",
      "        106, 109,   0, 106, 130, 128, 106, 105, 131, 108,   0, 107, 131, 106,\n",
      "          0, 127, 136,   0, 115, 130, 129,   0, 106, 130, 132, 106, 117, 112,\n",
      "        136, 132,   0, 131, 132,   0, 106, 130, 131, 114, 132, 136, 136, 132,\n",
      "          0, 106, 130, 102, 107, 116, 136, 106, 100,   0, 106, 130, 115, 136,\n",
      "        132,   0, 124, 106, 132, 134, 106,   0, 111, 116, 106, 100,   0, 106,\n",
      "        130, 102, 112, 114, 106, 110,   0, 106, 130, 131, 117, 124, 117, 124,\n",
      "        108,   0, 130, 130, 106, 118, 109, 128, 116, 106, 116,   0, 134, 106,\n",
      "        130, 124, 131, 130, 136, 106, 109,   0, 106, 130, 104, 116, 133, 106,\n",
      "        107, 136, 108,  12,   0, 134, 114, 124, 106,   0, 106, 130, 131, 111,\n",
      "        130, 118,   0, 106, 130, 104, 114, 106, 116, 108,   0, 106, 130, 102,\n",
      "        131, 116, 136, 129, 136, 108,   0, 134,   0, 106, 130, 131, 111, 109,\n",
      "        131, 124,   0, 106, 130, 114, 134, 130, 136,   0, 131, 118, 106, 124,\n",
      "        114, 108,   0, 106, 130, 136, 131, 132,   0, 107, 129, 130,   0, 106,\n",
      "        130, 118, 107, 130,   0, 106, 130, 131, 109, 106, 112, 108,   0, 130,\n",
      "        109, 124, 117, 136, 117,   0, 128, 114, 116, 106, 109, 133,   0, 127,\n",
      "        136,   0, 131, 134, 106, 111, 133, 108,   0, 106, 130, 104, 116, 133,\n",
      "        106, 107,   0, 134, 106, 130, 112, 136, 130, 134, 130, 108,   0, 114,\n",
      "        134, 132,   0, 109, 114, 133, 134, 116,   0, 102, 134, 121, 106, 124,\n",
      "        133,   0, 106, 130, 102, 131, 132, 136, 108,   0, 134, 106, 130, 112,\n",
      "        127, 106, 123,   0, 124, 130, 135,   0, 106, 118, 109, 128, 116, 106,\n",
      "        116, 133,  12,   0, 127, 136,   0, 112, 136, 132,   0, 119, 114, 114,\n",
      "          0, 106, 130, 118, 136, 132, 106, 109, 134, 116,   0, 106, 130, 114,\n",
      "        136, 131, 128, 116, 106, 122, 136,   0, 107, 132, 111, 106, 131, 136,\n",
      "        132,   0, 129, 106, 116, 114, 106, 132,   0, 106, 130, 115, 136,   0,\n",
      "        109, 107, 132, 135,   0, 106, 130, 128, 116, 106, 116,   0, 131, 124,\n",
      "          0, 106, 130, 118, 136, 132, 106, 109, 134, 116,   0, 106, 130, 111,\n",
      "        131, 133, 134, 116, 136,   0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 14,  22,  13, 114, 136, 118, 131, 107, 116])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size=8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([14]) the target: 22\n",
      "when input is tensor([14, 22]) the target: 13\n",
      "when input is tensor([14, 22, 13]) the target: 114\n",
      "when input is tensor([ 14,  22,  13, 114]) the target: 136\n",
      "when input is tensor([ 14,  22,  13, 114, 136]) the target: 118\n",
      "when input is tensor([ 14,  22,  13, 114, 136, 118]) the target: 131\n",
      "when input is tensor([ 14,  22,  13, 114, 136, 118, 131]) the target: 107\n",
      "when input is tensor([ 14,  22,  13, 114, 136, 118, 131, 107]) the target: 116\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      "torch.Size([4, 8])\n",
      "tensor([[124,   0, 106, 130, 106, 132, 106, 116],\n",
      "        [132,   0, 106, 130, 115, 136,   0, 106],\n",
      "        [112, 109, 131, 130, 108,   2,   0, 127],\n",
      "        [  0, 134, 106, 112, 114, 106,   0, 131]])\n",
      "Targets: \n",
      "torch.Size([4, 8])\n",
      "tensor([[  0, 106, 130, 106, 132, 106, 116, 108],\n",
      "        [  0, 106, 130, 115, 136,   0, 106, 128],\n",
      "        [109, 131, 130, 108,   2,   0, 127, 136],\n",
      "        [134, 106, 112, 114, 106,   0, 131, 132]])\n",
      "----\n",
      "when input is [124] the target: 0\n",
      "when input is [124, 0] the target: 106\n",
      "when input is [124, 0, 106] the target: 130\n",
      "when input is [124, 0, 106, 130] the target: 106\n",
      "when input is [124, 0, 106, 130, 106] the target: 132\n",
      "when input is [124, 0, 106, 130, 106, 132] the target: 106\n",
      "when input is [124, 0, 106, 130, 106, 132, 106] the target: 116\n",
      "when input is [124, 0, 106, 130, 106, 132, 106, 116] the target: 108\n",
      "when input is [132] the target: 0\n",
      "when input is [132, 0] the target: 106\n",
      "when input is [132, 0, 106] the target: 130\n",
      "when input is [132, 0, 106, 130] the target: 115\n",
      "when input is [132, 0, 106, 130, 115] the target: 136\n",
      "when input is [132, 0, 106, 130, 115, 136] the target: 0\n",
      "when input is [132, 0, 106, 130, 115, 136, 0] the target: 106\n",
      "when input is [132, 0, 106, 130, 115, 136, 0, 106] the target: 128\n",
      "when input is [112] the target: 109\n",
      "when input is [112, 109] the target: 131\n",
      "when input is [112, 109, 131] the target: 130\n",
      "when input is [112, 109, 131, 130] the target: 108\n",
      "when input is [112, 109, 131, 130, 108] the target: 2\n",
      "when input is [112, 109, 131, 130, 108, 2] the target: 0\n",
      "when input is [112, 109, 131, 130, 108, 2, 0] the target: 127\n",
      "when input is [112, 109, 131, 130, 108, 2, 0, 127] the target: 136\n",
      "when input is [0] the target: 134\n",
      "when input is [0, 134] the target: 106\n",
      "when input is [0, 134, 106] the target: 112\n",
      "when input is [0, 134, 106, 112] the target: 114\n",
      "when input is [0, 134, 106, 112, 114] the target: 106\n",
      "when input is [0, 134, 106, 112, 114, 106] the target: 0\n",
      "when input is [0, 134, 106, 112, 114, 106, 0] the target: 131\n",
      "when input is [0, 134, 106, 112, 114, 106, 0, 131] the target: 132\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size=4\n",
    "block_size=8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split=='train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch(\"train\")\n",
    "print('Input: ')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "\n",
    "print('Targets: ')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print(\"----\")\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[124,   0, 106, 130, 106, 132, 106, 116],\n",
       "        [132,   0, 106, 130, 115, 136,   0, 106],\n",
       "        [112, 109, 131, 130, 108,   2,   0, 127],\n",
       "        [  0, 134, 106, 112, 114, 106,   0, 131]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 160])\n",
      "Loss 5.571990013122559\n",
      " ““cظLج­ـ-«Q5fة1صئ07س’_I%إ…TgJىلف[@ه}…ئ8Kذ0XأPLT’5fّ$tZ$ع:­إ(}ؤ$a?fEحA:ّY‍Fرn_ؤ| C5“«\"bْع؟لصصBوف?o\"Sع\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(2024)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, target=None):\n",
    "\n",
    "        logits = self.token_embedding_table(idx) # (Batch, Time, Channel). Channel is coming from the Embedding layer for each one of the input\n",
    "        \n",
    "        if target is None:\n",
    "            return logits, None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C) # This squach the two first dimensions B and T so that C is the second to comply with cross entropy\n",
    "            target = target.view(B*T)\n",
    "            loss = F.cross_entropy(logits, target) # Cross entropy would expect (Batch, Channel, Time)\n",
    "            return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx) # Get the prediction\n",
    "\n",
    "            logits = logits[:, -1, :] # Focus only on the last timestep => (B, C) because T becomes 1\n",
    "\n",
    "            probs = F.softmax(logits, dim=-1)  # Apply softmax converts to probabilites across the Channels\n",
    "\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # We sample from the prob distribution to get the next token (B, 1)\n",
    "\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # Concatenate the token with the existing sequence (B, T+1)\n",
    "        \n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size=vocab_size)\n",
    "out, loss = m(xb, yb)\n",
    "print(out.shape)\n",
    "print(f\"Loss {loss}\")\n",
    "\n",
    "\n",
    "print(''.join(decode(m.generate(idx=torch.zeros((1,1), dtype=torch.long), max_new_tokens=100)[0].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehditantaoui/Documents/Challenges/GenerativeAI/transformers/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.481208324432373\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for steps in range(10000):\n",
    "\n",
    "    xb, yb = get_batch(\"train\")\n",
    "\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " كلوان د تعن الحرية حالأنهد انستفة الإلق \"صرة فا عالالللار. الميحاسبدن سوحاجاء بعز بة الحرضحزيلك، الى\n"
     ]
    }
   ],
   "source": [
    "print(''.join(decode(m.generate(idx=torch.zeros((1,1), dtype=torch.long), max_new_tokens=100)[0].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
